---
title: "PS7 - Data Distributions"
format: pdf
jupyter: python3
---

# Introduction

Please watch [The Shape of Data: Distributions](https://youtu.be/bPFNxD3Yg6U/) before starting the problem set.

# Setup

In addition to looking at real world data, we also will generate some of our own data using a random number generator. `random` module from the `numpy` package.

```{python}

import statistics as st
import numpy as np
import numpy.random as rand
import matplotlib.pyplot as plt
import matplotlib.ticker as tck # load the ticker module of matplotlib

#create random number generator
rng = rand.default_rng(seed=3289) #set seed so that our results are replicable

#generate some random numbers
r1d6 = rng.choice(range(1, 7), size=10000) # 10,000 simulated rolls of a 6-sided die.

```

```{python}
#| echo: false

price_bins = 40

def NumericMode(v, bins):
    h = np.histogram(v, bins=bins)
    max_bin = np.argmax(h[0])
    n_mode = (h[1][max_bin] + h[1][max_bin+1])/2

    return(n_mode)


def CalcStats(v, digits=2, isInt = True, bins=30):
    d = {
    'mu': np.mean(v).round(digits),
    'std': np.std(v).round(digits)
    }
    
    if isInt:
        d['med'] = int(np.median(v)),
        d['mode'] = st.mode(v)
    
    else: 
        d['med'] = np.median(v).round(digits)
        d['mode'] = NumericMode(v, bins)

    return d

```

# Distributions

A data distribution tells you how frequently a particular value appears in a data set. This can be expressed as a count ("frequency"), or it can be expressed as a likelihood ("probability"). In the setup code, we simulated 10,000 rolls of a 6-sided die. The frequency of 4 for that particular set of rolls was 1656. The probability of getting a 4 for that set of rolls was 0.1656, or approximately 16.6%. While both frequencies and probabilities can be useful, we see probabilities used more frequently in real life situations. This is because it is easier to compare between data sets. While can choose how much data we want to simulate in a computer program, scientists often don't have that option in real life.

Figure 1 depicts the frequency distribution of rolls from our simulated data. Figure 2 shows the probability distribution. 

```{python}

bins = np.arange(1, 6 + 1.5) - 0.5 #set up bins for histogram

fig1, ax1 = plt.subplots()

ax1.hist(r1d6, bins=bins, rwidth=0.9, edgecolor='black')
ax1.set_title("Figure 1. Data Distribution of Rolling a 6-sided Die 10,000 times (Frequency)")
ax1.set_xlabel('Outcome (possible roll)')
ax1.set_ylabel('Frequency')
plt.show()


```

```{python}

bins = np.arange(1, 6 + 1.5) - 0.5 #set up bins for histogram

fig2, ax2 = plt.subplots()

ax2.hist(r1d6, bins=bins, rwidth=0.9, edgecolor='black', density=True)
ax2.set_ylim([0,1])
ax2.set_title("Figure 2. Data Distribution of Rolling a 6-sided Die 10,000 times (Probability)")
ax2.set_xlabel('Outcome (possible roll)')
ax2.set_ylabel('Probability')
plt.show()


```



# Describing Distributions

When we describe distributions, we can describe them qualitatively and quantitatively. 

## Distribution Characteristics (Qualitative)

* continuous or discrete
* Symmetric or skewed
* Unimodal or multi-modal

Distributions have a number of characteristics that we can use to describe them. They can be continous or discrete. Continous distributions are distributions that can take on any value, within a given range. Human heights are continuously distributed, as is the length of time it takes people to run 100m. Discrete distributions can only take on specific values. Dice rolls have a discrete distribution, as do the number of times people have eaten ice cream in the past week.

Distributions can also be symmetric or skewed. Symmetric distributions are distributions that look the same if you fold them in half. Our simulated die rolls have a roughly symmetric distributions.

Skewed distributions have more data on one side of the distribution than the other. A distribution is positively (or right) skewed if it has a long tail to the right. Income levels in the United States are right skewed, as are housing prices (Figure 3). A distribution is negatively (or left) skewed if it has a long tail to the left. Age of non-accidental death in the United States is negatively skewed.

```{python}
#| echo: false
import pandas as pd

sales = pd.read_csv('data/raw_sales.csv')
sales = sales.loc[sales.propertyType=='house'] 

#Converting datestring to datetime class
sales['datesold'] = pd.to_datetime(sales['datesold'], format="%Y-%m-%d %H:%M:%S")

# Extracting year from datetime class
sales['Year'] = sales.datesold.dt.year

sales17 = sales.loc[sales.Year==2017]

price17_2M = np.where(sales17.price>3e6, 3e6, sales17.price)

def ToThousands(x, pos): #function to convert number to thousands
    kn = round(x/1000) # divide by 1000 and turn into an integer
    kn_str = "{:,}".format(kn) + 'k' #add a k on the end to denote thousands
    if x>=3e6:
        kn_str = '> ' + kn_str
    return kn_str

fig3, ax3 = plt.subplots()

ax3.hist(price17_2M, bins=price_bins)
ax3.xaxis.set_major_formatter(tck.FuncFormatter(ToThousands))
ax3.tick_params(axis='x', labelrotation = 45) #rotate x axis labels 
ax3.set_title("Figure 3. Histogram of 2017 Home Sales Prices in New England \n(Right Skewed)")
ax3.set_xlabel('Price ($)')
ax3.set_ylabel('Number of Houses')
plt.show()


```


The mode of a dataset is the most common value. The mode of a distribution is the peak frequency or probability. Most data distributions we see on a regular basis are uni-modal, meaning they only have one peak. This includes almost all the examples previously mentioned. Some distributions have more than one peak though. This was the case for age of death prior to modern medicine. Many people died in childhood, but if you survived childhood you were fairly likely to live into your 50s or 60s. This resulted in a bimodal distribution of age of death.

## Distribution Statistics (Quantitative)

In addition to these characteristics, we can also describe a distribution using a number of different statistics:

* mean ($\mu$)
* standard deviation ($\sigma$)
* median
* mode

The mean and standard deviation are particularly important, so we give them their own special symbols. We can use python to calculate these statistics fairly easily for our siimulated dice rolls with functions we've already used.

```{python}
#| echo: false

d6stats = CalcStats(r1d6)

from IPython.display import display, Markdown

display(Markdown("""
For this sumulation the mean value of our die rolls was {d6mean}, the median was {d6median}, the mode was {d6mode}, and the standard deviation was {d6st_dev}. For a different set of 10,000 simulated rolls, some of the numbers would change. The mode in particular can change quite a bit 
""".format(d6mean = d6stats['mu'], d6median=d6stats['med'], d6mode=d6stats['mode'],d6st_dev=d6stats['std'])))
```


The qualitative characteristics of our distribution can have a large effect on the statistics of our distribution. In particular, the skew of a distribution has a predictable effect on the mean, median and mode. In a symmetric distribution, the mean, median, and mode are all close together, at the peak of the distribution. In a skewed distribution, the mode is still at the peak of the distribution. However, the mean is further toward the tail. The median generally falls in between the mean and the mode, for skewed distributions.

```{python}
#| echo: false

pstats = CalcStats(sales17.price, isInt=False, bins=price_bins)

norm_price = rng.normal(loc=pstats['mode'], scale=pstats['std'], size=len(sales17.price))
norm_price2M = np.where(norm_price>3e6, 3e6, norm_price)

nstats = CalcStats(norm_price, isInt=False, bins=price_bins)

fig4, ax4 = plt.subplots(nrows=2, sharex=True)

ax4[0].hist(price17_2M, bins=price_bins)
ax4[0].axvline(x=pstats['mu'], color = 'black', linestyle='dashed')
ax4[0].axvline(x=pstats['med'], color = 'black', linestyle='dotted')
ax4[0].axvline(x=pstats['mode'], color = 'black', linestyle='solid')
ax4[0].xaxis.set_major_formatter(tck.FuncFormatter(ToThousands))
ax4[0].tick_params(axis='x', labelrotation = 45) #rotate x axis labels 
ax4[0].set_title("")
ax4[0].set_ylabel('Actual Sales')

ax4[1].hist(norm_price2M, bins=price_bins)
ax4[1].axvline(x=nstats['mu'], color = 'black', linestyle='dashed')
ax4[1].axvline(x=nstats['med'], color = 'black', linestyle='dotted')
ax4[1].axvline(x=nstats['mode'], color = 'black', linestyle='solid')
ax4[1].xaxis.set_major_formatter(tck.FuncFormatter(ToThousands))
ax4[1].tick_params(axis='x', labelrotation = 45) #rotate x axis labels 
ax4[1].set_xlabel('Price ($)')
ax4[1].set_ylabel('Simulated Sales\n(simulated)')


fig4.suptitle('Figure 4. Mean, Median, and Mode for Symmetric and Skewed Distributions', fontsize=16)
plt.show()


```



# Density and Binning

When plotting the probability distribution of the outcomes of a 6-sided die roll, we set `density=True` to tell python to calculate probabilities instead of frequencies. However density is not always the same as probabilitity, and the value of density doesn't just depend on the data itself.

Density depends on what data you have, the size of the bins that you use to group your data, and the locations of those bins. In a density plot, the area of all of the bins will always add to 1. This means that if the width of the bin is less than 1, the value of the bar in the histogram can be greater than 1, even though it's not possible for something to have a greater than 100% chance of happening. 

If we simulate two sets of data using two different distributions we can see how the size of the bins affects the density. In Figure 5A and B, the width of the bins are exactly 1, so the bin densities do correspond to the probability. Notice no more than one of the bins has a density of greater than 0.5. However in Figures 5C and D, the bin widths are much smaller and so there are quite a few densities that have a value of greater than 0.5.

The density plotted depends on the location of the bins, in addition to their width. Figure 5A and 5B, both have the same bin width (1). However, their bins are offset from each other. Figure 5A has bins that end on the integers (-5 to -4, -4 to -3 etc), while Figure 5B has bins that end on the half steps (-5.5 to -4.5, -4.5 to -3.5 etc). Even though the blue and orange data in Figures 5A and 5B are the same, the blue distribution in Figure 5B looks much more narrow compared to the orange distribution. 


```{python}

#generate some random numbers
normX = rng.normal(0, 0.5, size=1000) # 10,000 normal(0, 0.5) data pulls
xlab = '$\mu=0$, $\sigma=0.5$'

normY = rng.normal(0, 1, size=1000) # 10,000 normal(0, 1) data pulls
ylab = '$\mu=0$, $\sigma=1$'



binorm = np.concatenate((rng.normal(0, 1, size=10000), rng.normal(3, 1, size=10000)))

binsA = np.arange(-5, 5) #set up bins for histogram 
binsB = np.arange(-5, 5.5) - 0.5 #set up bins for histogram (Offset)


fig5, ax5 = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True,
figsize=(8, 6))

ax5[0,0].hist(normX, bins=binsA, density=True, alpha=0.7, label=xlab)
ax5[0,0].hist(normY, bins=binsA, density=True, alpha=0.7, label=ylab)
ax5[0,0].annotate('A. Bin width = 1', xy=(-5.4,0.75))

ax5[0,1].hist(normX, bins=binsB, density=True, alpha=0.7, label=xlab)
ax5[0,1].hist(normY, bins=binsB, density=True, alpha=0.7, label=ylab)
ax5[0,1].annotate('B. Bin width = 1, offset', xy=(-5.4,0.75))


ax5[1,0].hist(normX, bins=15, density=True, alpha=0.7, label=xlab)
ax5[1,0].hist(normY, bins=15, density=True, alpha=0.7, label=ylab)
ax5[1,0].annotate('C. Bin width ~ 0.2', xy=(-5.4,0.75))

ax5[1,1].hist(normX, bins=40, density=True, alpha=0.7, label=xlab)
ax5[1,1].hist(normY, bins=40, density=True, alpha=0.7, label=ylab)
ax5[1,1].annotate('D. Bin width ~ 0.08', xy=(-5.4,0.75))

handles, labels = ax5[1,1].get_legend_handles_labels()
fig5.legend(handles, labels, loc='lower center')

fig5.suptitle('Figure 5. Randomly generated data with different binning schemes')

#removing space between the plots both horizontally and vertically
plt.subplots_adjust(wspace=0, hspace=0, top=0.95, bottom=0.15)

plt.show()

fig6, ax6 = plt.subplots()

ax6.hist(binorm, bins=8, density=True, alpha=0.6)
ax6.hist(binorm, bins=30, density=True, alpha=0.6)

plt.show()


```


# Specific Distributions

Some distributions are so common or important we have given them special names. We will cover two in this problem set: Uniform distributions and Normal Distributions. 

## Uniform distribution

A uniform distribution is any distribution where all outcomes have the same likelihood of happening. They are *symmetric*, they can be *discrete* or *continuous*, and they do not have a mode. This is because, if all the  The outcome of rolling a single die has a discrete uniform distribution. We can simulate this using the `choice()` method. Continous uniform distributions are not common in the real world. However, they can be used to simulate data using the `uniform()` method. 

## Normal Distribution

The normal distribution is probably the most common distribution. It is also frequently called a 'bell shaped curve' or a gaussian distribution. Be warned though, there are other curves that look similar that are not actually normal distributions. The normal distribution is *continuous*, *symmetric* and *unimodal*. 



# Questions
1. Frequencies vs. Probabilities

    a. What is a specific situation where you would care as much about the frequencies of the data as you care about their probability?
    b. What is a specific situation where only the data probability is important?

2. Simulating Dice Rolls
    a. Simulate 10,000 rolls of 2 6-sided dice, where the outcome is the sum of the dice added together.
    b. Plot the frequencies of the data you just simulated.
    c. Plot the probabilities of your simulated dice roll data.

3. Describing your Dice Rolls
    a. Describe the distribution of the dice rolls you simulated using the terminology from the Distribution Characteristics section. 
    b. Calculate the mean, median, mode, and standard deviation for your dice roll data.

4. Would we expect any of the mean, median, mode, and standard deviation to change very much between different sets of simulations for rolling a single die? How about for rolling 2 dice?

5. Numeric Mode
    a. If you use the `st.mode()` function on a data series without any repeat values (ex. housing prices), what number does it return?
    b. Write a function called `NumericMode()` that provides a more useful output for a distribution of (non-repeating) numbers

5. Plotting Real World Data
    a. Plot the distribution of a variable in your dataset using the default values for `hist()`
    b.  Plot the distribution of the same variable using 2 different numbers of bins.
    c. Plot the same variable, but offset the bin cutoffs.
    d. How did each of the plots in a-c change the way you thought about your data?

5. Real World Data Distributions
    
    b. How does the shape of the distribution change with the number of bins you use?
    b. Estimate the mean, median, and mode visually based on your plot.
    c. Calculate the mean, median, mode, and standard deviation of your data. Use the `NumericMode()` from the previous question. How far off were your estimates?

6. What are the arguments of `uniform()` and what do they do?

7. What are the arguments of `normal()` and what do they do?